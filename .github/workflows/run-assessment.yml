name: Run Portfolio Assessment

on:
  push:
    branches: [main]
    paths:
      - 'scenario.toml'
      - '.github/workflows/run-assessment.yml'
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      scenario_count:
        description: 'Number of scenarios to run (1-5)'
        required: false
        default: '5'

env:
  PURPLE_IMAGE: ghcr.io/rachnog/portfolio-constructor:v1.0
  GREEN_IMAGE: ghcr.io/rachnog/portfolio-evaluator:v1.0

jobs:
  run-assessment:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Pull Docker images
        run: |
          echo "Pulling agent images..."
          docker pull ${{ env.PURPLE_IMAGE }}
          docker pull ${{ env.GREEN_IMAGE }}

      - name: Verify images
        run: |
          docker images | grep portfolio

      - name: Create Docker network
        run: |
          docker network create agentbeats-network

      - name: Start Purple Agent (Constructor)
        run: |
          docker run -d \
            --name purple-agent \
            --network agentbeats-network \
            -p 9019:9019 \
            -e GOOGLE_API_KEY=${{ secrets.GOOGLE_API_KEY }} \
            -e CONSTRUCTOR_MODEL=gemini-2.0-flash \
            ${{ env.PURPLE_IMAGE }}

      - name: Start Green Agent (Evaluator)
        run: |
          docker run -d \
            --name green-agent \
            --network agentbeats-network \
            -p 9009:9009 \
            -e GOOGLE_API_KEY=${{ secrets.GOOGLE_API_KEY }} \
            -e EVALUATOR_MODEL=gemini-2.0-flash \
            ${{ env.GREEN_IMAGE }}

      - name: Wait for agents to be ready
        run: |
          echo "Waiting for agents to start..."
          sleep 10

          echo "Checking Purple Agent health..."
          for i in {1..30}; do
            if curl -sf http://localhost:9019/.well-known/agent-card.json > /dev/null; then
              echo "✅ Purple Agent is ready"
              break
            fi
            echo "Waiting for Purple Agent... ($i/30)"
            sleep 2
          done

          echo "Checking Green Agent health..."
          for i in {1..30}; do
            if curl -sf http://localhost:9009/.well-known/agent-card.json > /dev/null; then
              echo "✅ Green Agent is ready"
              break
            fi
            echo "Waiting for Green Agent... ($i/30)"
            sleep 2
          done

      - name: Verify agent cards
        run: |
          echo "=== Purple Agent Card ==="
          curl -s http://localhost:9019/.well-known/agent-card.json | jq .

          echo ""
          echo "=== Green Agent Card ==="
          curl -s http://localhost:9009/.well-known/agent-card.json | jq .

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install requests pydantic

      - name: Run Assessment
        id: assessment
        run: |
          python - <<'EOF'
          import json
          import requests
          import time
          from datetime import datetime

          # Test scenarios
          scenarios = [
              {
                  "id": "house_down_payment_5yr",
                  "goal": "I want to save $50,000 for a house down payment in 5 years. I currently have $10,000 saved and can invest $500 per month. My risk tolerance is moderate."
              }
          ]

          results = []

          for scenario in scenarios:
              print(f"\n{'='*60}")
              print(f"Running scenario: {scenario['id']}")
              print(f"{'='*60}\n")

              start_time = time.time()

              try:
                  # Call Green Agent with AgentBeats EvalRequest format
                  # Green agent will internally call purple agent
                  print(f"Calling Green Agent for scenario: {scenario['id']}")

                  eval_request = {
                      "participants": {
                          "portfolio_constructor": "http://purple-agent:9019/"
                      },
                      "config": {
                          "goal_description": scenario["goal"]
                      }
                  }

                  print(f"EvalRequest: {json.dumps(eval_request, indent=2)}")

                  green_response = requests.post(
                      'http://localhost:9009/',
                      json={
                          "jsonrpc": "2.0",
                          "method": "message/send",
                          "params": {
                              "message": {
                                  "messageId": f"eval-{scenario['id']}-{int(time.time())}",
                                  "role": "user",
                                  "parts": [
                                      {
                                          "kind": "text",
                                          "text": json.dumps(eval_request)
                                      }
                                  ]
                              }
                          },
                          "id": 1
                      },
                      timeout=120
                  )

                  print(f"Green Agent HTTP Status: {green_response.status_code}")
                  print(f"Green Agent Response: {green_response.text[:1000]}")

                  evaluation_data = green_response.json()

                  # Extract results from A2A Task response
                  portfolio_content = None
                  evaluation_content = None

                  if 'result' in evaluation_data:
                      result = evaluation_data['result']

                      # Check for artifacts (contain the evaluation results)
                      if 'artifacts' in result:
                          for artifact in result['artifacts']:
                              if 'parts' in artifact:
                                  for part in artifact['parts']:
                                      if part.get('kind') == 'text':
                                          artifact_text = part.get('text', '')
                                          try:
                                              artifact_data = json.loads(artifact_text)
                                              if 'portfolio' in artifact_data:
                                                  portfolio_content = artifact_data['portfolio']
                                              if 'evaluation' in artifact_data:
                                                  evaluation_content = artifact_data['evaluation']
                                          except:
                                              pass

                      # Also check status message
                      if 'status' in result and 'message' in result['status']:
                          status_parts = result['status']['message'].get('parts', [])
                          for part in status_parts:
                              if part.get('kind') == 'text':
                                  print(f"Status message: {part.get('text', '')[:500]}")

                  execution_time = (time.time() - start_time) * 1000

                  # Compile result
                  result = {
                      "scenario_id": scenario["id"],
                      "goal": scenario["goal"],
                      "portfolio": portfolio_content,
                      "evaluation": evaluation_content,
                      "execution_time_ms": int(execution_time),
                      "timestamp": datetime.utcnow().isoformat(),
                      "purple_agent": "portfolio_constructor",
                      "green_agent": "portfolio_evaluator"
                  }

                  results.append(result)
                  print(f"\n✅ Scenario completed in {execution_time:.0f}ms")

              except Exception as e:
                  print(f"❌ Error running scenario: {str(e)}")
                  import traceback
                  traceback.print_exc()
                  continue

          # Save results
          import os
          os.makedirs('results', exist_ok=True)

          with open('results/assessment_results.json', 'w') as f:
              json.dump(results, f, indent=2)

          print(f"\n{'='*60}")
          print(f"✅ Assessment complete! {len(results)} scenarios evaluated")
          print(f"{'='*60}")
          EOF

      - name: Create results directory
        run: |
          mkdir -p results artifacts

      - name: Save results
        run: |
          echo '{"status": "completed", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "scenarios": 3}' > results/summary.json

      - name: Display agent logs
        if: always()
        run: |
          echo "=== Purple Agent Logs ==="
          docker logs purple-agent --tail 100

          echo ""
          echo "=== Green Agent Logs ==="
          docker logs green-agent --tail 100

      - name: Stop containers
        if: always()
        run: |
          docker stop purple-agent green-agent || true
          docker rm purple-agent green-agent || true
          docker network rm agentbeats-network || true

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: assessment-results
          path: |
            results/
            artifacts/
          retention-days: 90

      - name: Create results PR
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "Add assessment results for ${{ github.sha }}"
          title: "Assessment Results - ${{ github.run_number }}"
          body: |
            ## Assessment Results

            **Run**: ${{ github.run_number }}
            **Commit**: ${{ github.sha }}
            **Date**: ${{ github.event.head_commit.timestamp }}

            ### Summary
            - Scenarios evaluated: 3
            - Purple Agent: portfolio_constructor
            - Green Agent: portfolio_evaluator

            Review the results and merge to update the leaderboard.
          branch: results/${{ github.run_number }}
          base: main
